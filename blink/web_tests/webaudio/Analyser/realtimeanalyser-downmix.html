<!DOCTYPE html>
<html>
  <head>
    <title>
      Test AnalyserNode Downmixing
    </title>
    <script src="../../resources/testharness.js"></script>
    <script src="../../resources/testharnessreport.js"></script>
    <script src="../resources/audit-util.js"></script>
    <script src="../resources/fft.js"></script>
    <script src="../resources/realtimeanalyser-testing.js"></script>
  </head>
  <body>
    <script>
      const sampleRate = 44100;
      const renderFrames = 2048;

      const testConfigs = [
        {channelCount: 1, message: 'mono', floatRelError: 6.3283e-8},
        {channelCount: 2, message: 'stereo', floatRelError: 1.1681e-7},
        {channelCount: 4, message: 'quad', floatRelError: 4.9793e-7},
        {channelCount: 6, message: '5.1', floatRelError: 2.0215e-7},
        {channelCount: 3, message: '3-channel', floatRelError: 6.3283e-8}
      ];

      // Create tests for each entry in testConfigs
      for (const config of testConfigs) {
        promise_test(async (t) => {
          await runTest(config);
        }, `Analyser downmix ${config.message} to mono`);
      }

      // Test downmixing of the AnalyserNode time data.  We use the downmixing
      // that automatically happens in the destination node to generate the
      // reference data which is compared to the data that the Analyser node has
      // captured.
      function runTest(options) {
        // Context MUST have exactly one channel so that we downmix the source
        // to mono to generate the reference.
        const context = new OfflineAudioContext(1, renderFrames, sampleRate);

        const channels = options.channelCount || 1;
        const source = context.createBufferSource();

        // The signals in each channel. Doesn't matter much what is in here, but
        // it's best if the values aren't linearly increasing so that the
        // average of the values isn't one of the values (in case the
        // implementation does something silly).  Only need to support up to 6
        // channels.
        const bufferValues = [1, 2, 3, 4, 5, 6].map((x) => x * x);
        source.buffer = createConstantBuffer(
            context, renderFrames, bufferValues.slice(0, channels));

        const analyser = context.createAnalyser();
        analyser.smoothingTimeConstant = 0;
        analyser.fftSize = 256;

        // Run analyser as an automatic pull node. Do NOT connect to the
        // destination.  We don't want the output of the analyser to mix in with
        // the source that is also directly connected to the destination.
        source.connect(analyser);
        source.connect(context.destination);

        const timeData = new Float32Array(analyser.fftSize);
        const freqData = new Float32Array(analyser.frequencyBinCount);

        const suspendFrame = analyser.fftSize;
        context.suspend(suspendFrame / context.sampleRate)
            .then(() => {
              analyser.getFloatTimeDomainData(timeData);
              analyser.getFloatFrequencyData(freqData);
            })
            .then(context.resume.bind(context));

        source.start();
        return context.startRendering().then((renderedBuffer) => {
          // Verify the time domain data is correct.
          const prefix = 'Analyser downmix ' + options.message + ' to mono';
          assert_array_equals(
              timeData,
              renderedBuffer.getChannelData(0).subarray(0, analyser.fftSize),
              prefix + ' time data');

          const expectedTimeData =
              renderedBuffer.getChannelData(0).subarray(0, analyser.fftSize);
          const fftOrder = Math.floor(Math.log2(analyser.fftSize));
          const expectedFreqData =
              computeFFTMagnitude(expectedTimeData, fftOrder).map(linearToDb);

          compareFloatFreq_W3CTH(
              prefix + ' freq data', freqData, expectedFreqData, {
                floatRelError: options.floatRelError,
              });
        });
      }
    </script>
  </body>
</html>
